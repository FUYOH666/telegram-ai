"""RAG —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–º–ø–∞–Ω–∏–∏/—É—Å–ª—É–≥–∞—Ö."""

import logging
from collections import defaultdict
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from .vector_memory import VectorMemory

logger = logging.getLogger(__name__)


class RAGSystem:
    """RAG —Å–∏—Å—Ç–µ–º–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏."""

    def __init__(
        self,
        vector_memory: Optional[VectorMemory] = None,
        enabled: bool = True,
        knowledge_base_path: Optional[str] = None,
        max_results: int = 3,
        min_score: float = 0.7,
        log_stats_interval: int = 100,
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã.

        Args:
            vector_memory: –≠–∫–∑–µ–º–ø–ª—è—Ä VectorMemory –¥–ª—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
            enabled: –í–∫–ª—é—á–∏—Ç—å RAG —Å–∏—Å—Ç–µ–º—É
            knowledge_base_path: –ü—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            max_results: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
            min_score: –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π score –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            log_stats_interval: –ò–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤)
        """
        self.enabled = enabled
        self.knowledge_base_path = Path(knowledge_base_path) if knowledge_base_path else None
        self.max_results = max_results
        self.min_score = min_score
        self.rag_collection = None
        self.rag_collection_name = None
        self.log_stats_interval = log_stats_interval

        # –ú–µ—Ç—Ä–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        self.total_queries = 0
        self.successful_queries = 0
        self.empty_results = 0
        self.total_chunks_found = 0
        self.scores: List[float] = []  # –í—Å–µ scores –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self.file_usage: Dict[str, int] = defaultdict(int)  # –°—á–µ—Ç—á–∏–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–æ —Ñ–∞–π–ª–∞–º

        # –°–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é –¥–ª—è RAG (–æ—Ç–¥–µ–ª—å–Ω–æ –æ—Ç –∏—Å—Ç–æ—Ä–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π)
        if enabled and vector_memory:
            self.vector_memory = vector_memory
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–¥–µ–ª—å–Ω—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é –¥–ª—è RAG
            self.rag_collection_name = "rag_knowledge_base"
            self._init_rag_collection()
        else:
            self.vector_memory = None
            logger.info("RAG system disabled")

    def _init_rag_collection(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é –¥–ª—è RAG –µ—Å–ª–∏ –Ω—É–∂–Ω–æ."""
        if not self.enabled or not self.vector_memory or not self.vector_memory.enabled:
            return

        try:
            # –°–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é –¥–ª—è RAG
            if self.vector_memory.client:
                self.rag_collection = self.vector_memory.client.get_or_create_collection(
                    name=self.rag_collection_name,
                    metadata={"hnsw:space": "cosine"},
                )
                logger.info(f"RAG collection initialized: {self.rag_collection_name}")
            else:
                self.rag_collection = None
        except Exception as e:
            logger.error(f"Error initializing RAG collection: {e}", exc_info=True)
            self.rag_collection = None
            self.enabled = False

    async def load_knowledge_base(self) -> int:
        """
        –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –∏–∑ knowledge_base_path –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ.

        Returns:
            –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        """
        if not self.enabled or not self.knowledge_base_path or not self.rag_collection:
            logger.warning("RAG system not enabled or knowledge base path not set")
            return 0

        if not self.knowledge_base_path.exists():
            logger.warning(f"Knowledge base path does not exist: {self.knowledge_base_path}")
            return 0

        loaded_count = 0
        skipped_count = 0
        total_chunks = 0

        try:
            # –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã (.txt, .md)
            supported_extensions = {".txt", ".md"}
            files = [
                f
                for f in self.knowledge_base_path.rglob("*")
                if f.is_file() and f.suffix.lower() in supported_extensions
            ]

            if not files:
                logger.warning(f"No supported files (.txt, .md) found in {self.knowledge_base_path}")
                return 0

            for file_path in files:
                try:
                    with open(file_path, "r", encoding="utf-8") as f:
                        content = f.read()

                    if not content.strip():
                        logger.debug(f"Skipping empty file: {file_path.name}")
                        continue

                    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞–Ω–∫–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–æ–∏—Å–∫–∞
                    chunks = self._split_into_chunks(content, chunk_size=500)
                    total_chunks += len(chunks)
                    file_loaded = 0
                    file_skipped = 0

                    for i, chunk in enumerate(chunks):
                        doc_id = f"doc_{file_path.stem}_{i}"
                        metadata = {
                            "file_path": str(file_path.relative_to(self.knowledge_base_path)),
                            "chunk_index": i,
                            "total_chunks": len(chunks),
                        }

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ —ç—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç
                        try:
                            existing = self.rag_collection.get(ids=[doc_id])
                            if existing and len(existing["ids"]) > 0:
                                # –î–æ–∫—É–º–µ–Ω—Ç —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                                file_skipped += 1
                                skipped_count += 1
                                continue
                        except Exception as e:
                            logger.debug(f"Error checking existing document {doc_id}: {e}")

                        # –ü–æ–ª—É—á–∞–µ–º embedding –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
                        embedding = await self.vector_memory.get_embedding(chunk)

                        if embedding:
                            self.rag_collection.add(
                                ids=[doc_id],
                                embeddings=[embedding],
                                documents=[chunk],
                                metadatas=[metadata],
                            )
                        else:
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ embeddings ChromaDB
                            self.rag_collection.add(
                                ids=[doc_id],
                                documents=[chunk],
                                metadatas=[metadata],
                            )

                        loaded_count += 1
                        file_loaded += 1

                    if file_loaded > 0:
                        logger.info(f"Loaded {file_loaded} new chunks from {file_path.name} (skipped {file_skipped} existing)")
                    elif file_skipped > 0:
                        logger.debug(f"All {file_skipped} chunks from {file_path.name} already exist, skipped")
                except Exception as e:
                    logger.error(f"Error loading file {file_path}: {e}", exc_info=True)
                    continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
            try:
                collection_count = self.rag_collection.count()
            except Exception:
                collection_count = 0

            if loaded_count > 0:
                logger.info(
                    f"Knowledge base loaded: {loaded_count} new chunks from {len(files)} files "
                    f"(skipped {skipped_count} existing, total in collection: {collection_count})"
                )
            elif skipped_count > 0:
                logger.info(
                    f"Knowledge base already loaded: {skipped_count} chunks from {len(files)} files "
                    f"already exist in collection (total: {collection_count})"
                )
            elif total_chunks == 0:
                logger.warning(
                    f"Knowledge base is empty: found {len(files)} files but no chunks extracted "
                    "(files may be empty or contain only whitespace)"
                )
            else:
                logger.warning(
                    f"Knowledge base loading issue: {len(files)} files processed, "
                    f"but no chunks were loaded (total chunks expected: {total_chunks})"
                )

            return loaded_count

        except Exception as e:
            logger.error(f"Error loading knowledge base: {e}", exc_info=True)
            return loaded_count

    def _split_into_chunks(self, text: str, chunk_size: int = 500, overlap: int = 50) -> List[str]:
        """
        –†–∞–∑–±–∏—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏ —Å –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º.

        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è
            chunk_size: –†–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞ –≤ —Å–∏–º–≤–æ–ª–∞—Ö
            overlap: –ü–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏ –≤ —Å–∏–º–≤–æ–ª–∞—Ö

        Returns:
            –°–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤
        """
        if len(text) <= chunk_size:
            return [text]

        chunks = []
        start = 0

        while start < len(text):
            end = start + chunk_size

            # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞–∑–±–∏—Ç—å –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º –¥–ª—è –ª—É—á—à–µ–π –≥—Ä–∞–Ω—É–ª—è—Ä–Ω–æ—Å—Ç–∏
            if end < len(text):
                # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ç–æ—á–∫—É/–ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏ –ø–µ—Ä–µ–¥ end
                last_period = text.rfind(".", start, end)
                last_newline = text.rfind("\n", start, end)

                if last_period > start or last_newline > start:
                    end = max(last_period, last_newline) + 1

            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)

            start = end - overlap

        return chunks

    async def search_relevant_info(self, query: str) -> List[Dict]:
        """
        –ù–∞–π—Ç–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π.

        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π:
            [{"content": str, "file_path": str, "score": float, ...}, ...]
        """
        if not self.enabled or not self.rag_collection:
            return []

        if not query or not query.strip():
            return []

        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        self.total_queries += 1

        try:
            # –ü–æ–ª—É—á–∞–µ–º embedding –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            query_embedding = await self.vector_memory.get_embedding(query)

            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
            if query_embedding:
                results = self.rag_collection.query(
                    query_embeddings=[query_embedding],
                    n_results=self.max_results,
                )
            else:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –ø–æ–∏—Å–∫
                results = self.rag_collection.query(
                    query_texts=[query],
                    n_results=self.max_results,
                )

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            found_info = []
            if results and "ids" in results and len(results["ids"]) > 0:
                for i, doc_id in enumerate(results["ids"][0]):
                    if i < len(results["metadatas"][0]) and i < len(results["documents"][0]):
                        metadata = results["metadatas"][0][i]
                        content = results["documents"][0][i]

                        # –ü–æ–ª—É—á–∞–µ–º score
                        distance = 0.0
                        if "distances" in results and len(results["distances"]) > 0:
                            distance = results["distances"][0][i]

                        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –≤ score
                        score = 1.0 - (distance / 2.0) if distance else 0.0

                        if score >= self.min_score:
                            file_path = metadata.get("file_path", "unknown")
                            found_info.append(
                                {
                                    "content": content,
                                    "file_path": file_path,
                                    "score": score,
                                    "chunk_index": metadata.get("chunk_index", 0),
                                }
                            )
                            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
                            self.scores.append(score)
                            self.file_usage[file_path] += 1

            # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            if found_info:
                self.successful_queries += 1
                self.total_chunks_found += len(found_info)
            else:
                self.empty_results += 1
                # –õ–æ–≥–∏—Ä—É–µ–º —Å–ª—É—á–∞–∏, –∫–æ–≥–¥–∞ RAG –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
                logger.debug(
                    f"RAG: No relevant info found for query '{query[:50]}...' "
                    f"(min_score={self.min_score:.2f})"
                )

            # –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π –≤—ã–∑–æ–≤
            scores_str = ", ".join([f"{info['score']:.2f}" for info in found_info])
            logger.debug(
                f"RAG query #{self.total_queries}: '{query[:50]}...' -> "
                f"{len(found_info)} chunks found (scores: [{scores_str}])"
            )

            # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            if self.total_queries % self.log_stats_interval == 0:
                self._log_statistics()

            return found_info

        except Exception as e:
            logger.error(f"Error searching RAG knowledge base: {e}", exc_info=True)
            self.empty_results += 1
            return []

    def format_context(self, found_info: List[Dict]) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–∞–π–¥–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤ –ø—Ä–æ–º–ø—Ç.

        Args:
            found_info: –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏

        Returns:
            –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è –≤ —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        """
        if not found_info:
            return ""

        context_parts = ["\n\nüìö **–†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:**\n"]

        for i, info in enumerate(found_info, 1):
            content = info["content"]
            file_path = info.get("file_path", "unknown")
            score = info.get("score", 0.0)

            context_parts.append(f"\n--- –§—Ä–∞–≥–º–µ–Ω—Ç {i} (–∏–∑ {file_path}, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {score:.2f}) ---\n{content}")

        context_parts.append(
            "\n\n‚ö†Ô∏è **–í–∞–∂–Ω–æ:** –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ –∫–æ–º–ø–∞–Ω–∏–∏/—É—Å–ª—É–≥–∞—Ö. "
            "–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—Ç —Ç–≤–æ–∏–º –∑–Ω–∞–Ω–∏—è–º, –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –∏–º–µ–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π."
        )

        return "\n".join(context_parts)

    def _log_statistics(self) -> None:
        """–õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è RAG —Å–∏—Å—Ç–µ–º—ã."""
        if self.total_queries == 0:
            return

        avg_score = sum(self.scores) / len(self.scores) if self.scores else 0.0
        min_score = min(self.scores) if self.scores else 0.0
        max_score = max(self.scores) if self.scores else 0.0
        success_rate = (self.successful_queries / self.total_queries * 100) if self.total_queries > 0 else 0.0

        logger.info(
            f"RAG Statistics (last {self.total_queries} queries): "
            f"successful={self.successful_queries} ({success_rate:.1f}%), "
            f"empty_results={self.empty_results}, "
            f"total_chunks={self.total_chunks_found}, "
            f"avg_score={avg_score:.3f}, "
            f"min_score={min_score:.3f}, "
            f"max_score={max_score:.3f}"
        )

        # –¢–æ–ø-5 –Ω–∞–∏–±–æ–ª–µ–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤
        if self.file_usage:
            top_files = sorted(self.file_usage.items(), key=lambda x: x[1], reverse=True)[:5]
            logger.debug(
                f"RAG Top files: {', '.join([f'{path} ({count})' for path, count in top_files])}"
            )

    def get_statistics(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è RAG —Å–∏—Å—Ç–µ–º—ã.

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π:
            {
                "total_queries": int,
                "successful_queries": int,
                "empty_results": int,
                "total_chunks_found": int,
                "success_rate": float,
                "avg_score": float,
                "min_score": float,
                "max_score": float,
                "top_files": List[Tuple[str, int]],
                "collection_count": int
            }
        """
        avg_score = sum(self.scores) / len(self.scores) if self.scores else 0.0
        min_score = min(self.scores) if self.scores else 0.0
        max_score = max(self.scores) if self.scores else 0.0
        success_rate = (self.successful_queries / self.total_queries * 100) if self.total_queries > 0 else 0.0

        # –¢–æ–ø-10 –Ω–∞–∏–±–æ–ª–µ–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö —Ñ–∞–π–ª–æ–≤
        top_files = sorted(self.file_usage.items(), key=lambda x: x[1], reverse=True)[:10]

        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        collection_count = 0
        if self.rag_collection:
            try:
                collection_count = self.rag_collection.count()
            except Exception:
                pass

        return {
            "total_queries": self.total_queries,
            "successful_queries": self.successful_queries,
            "empty_results": self.empty_results,
            "total_chunks_found": self.total_chunks_found,
            "success_rate": success_rate,
            "avg_score": avg_score,
            "min_score": min_score,
            "max_score": max_score,
            "top_files": top_files,
            "collection_count": collection_count,
        }

    def reset_statistics(self) -> None:
        """–°–±—Ä–æ—Å–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è RAG —Å–∏—Å—Ç–µ–º—ã."""
        self.total_queries = 0
        self.successful_queries = 0
        self.empty_results = 0
        self.total_chunks_found = 0
        self.scores.clear()
        self.file_usage.clear()
        logger.info("RAG statistics reset")

